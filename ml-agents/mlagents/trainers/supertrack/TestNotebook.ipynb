{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32me:\\Unity Projects\\python_env\\mlagents-20-clone\\ml-agents\\ml-agents\\mlagents\\trainers\\supertrack\\TestNotebook.ipynb Cell 1\u001b[0m line \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/Unity%20Projects/python_env/mlagents-20-clone/ml-agents/ml-agents/mlagents/trainers/supertrack/TestNotebook.ipynb#W0sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtime\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/e%3A/Unity%20Projects/python_env/mlagents-20-clone/ml-agents/ml-agents/mlagents/trainers/supertrack/TestNotebook.ipynb#W0sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/Unity%20Projects/python_env/mlagents-20-clone/ml-agents/ml-agents/mlagents/trainers/supertrack/TestNotebook.ipynb#W0sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtest_process\u001b[39m(queue):\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/Unity%20Projects/python_env/mlagents-20-clone/ml-agents/ml-agents/mlagents/trainers/supertrack/TestNotebook.ipynb#W0sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mTest process started\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32me:\\Unity Projects\\python_env\\mlagents-20-env\\lib\\site-packages\\torch\\__init__.py:1239\u001b[0m\n\u001b[0;32m   1237\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorch\u001b[39;00m \u001b[39mimport\u001b[39;00m special \u001b[39mas\u001b[39;00m special\n\u001b[0;32m   1238\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mbackcompat\u001b[39;00m\n\u001b[1;32m-> 1239\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorch\u001b[39;00m \u001b[39mimport\u001b[39;00m onnx \u001b[39mas\u001b[39;00m onnx\n\u001b[0;32m   1240\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorch\u001b[39;00m \u001b[39mimport\u001b[39;00m jit \u001b[39mas\u001b[39;00m jit\n\u001b[0;32m   1241\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorch\u001b[39;00m \u001b[39mimport\u001b[39;00m linalg \u001b[39mas\u001b[39;00m linalg\n",
      "File \u001b[1;32me:\\Unity Projects\\python_env\\mlagents-20-env\\lib\\site-packages\\torch\\onnx\\__init__.py:12\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_C\u001b[39;00m \u001b[39mimport\u001b[39;00m _onnx \u001b[39mas\u001b[39;00m _C_onnx\n\u001b[0;32m      5\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_C\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_onnx\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[0;32m      6\u001b[0m     _CAFFE2_ATEN_FALLBACK,\n\u001b[0;32m      7\u001b[0m     OperatorExportTypes,\n\u001b[0;32m      8\u001b[0m     TensorProtoDataType,\n\u001b[0;32m      9\u001b[0m     TrainingMode,\n\u001b[0;32m     10\u001b[0m )\n\u001b[1;32m---> 12\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m (  \u001b[39m# usort:skip. Keep the order instead of sorting lexicographically\u001b[39;00m\n\u001b[0;32m     13\u001b[0m     _deprecation,\n\u001b[0;32m     14\u001b[0m     errors,\n\u001b[0;32m     15\u001b[0m     symbolic_caffe2,\n\u001b[0;32m     16\u001b[0m     symbolic_helper,\n\u001b[0;32m     17\u001b[0m     symbolic_opset7,\n\u001b[0;32m     18\u001b[0m     symbolic_opset8,\n\u001b[0;32m     19\u001b[0m     symbolic_opset9,\n\u001b[0;32m     20\u001b[0m     symbolic_opset10,\n\u001b[0;32m     21\u001b[0m     symbolic_opset11,\n\u001b[0;32m     22\u001b[0m     symbolic_opset12,\n\u001b[0;32m     23\u001b[0m     symbolic_opset13,\n\u001b[0;32m     24\u001b[0m     symbolic_opset14,\n\u001b[0;32m     25\u001b[0m     symbolic_opset15,\n\u001b[0;32m     26\u001b[0m     symbolic_opset16,\n\u001b[0;32m     27\u001b[0m     symbolic_opset17,\n\u001b[0;32m     28\u001b[0m     symbolic_opset18,\n\u001b[0;32m     29\u001b[0m     utils,\n\u001b[0;32m     30\u001b[0m )\n\u001b[0;32m     32\u001b[0m \u001b[39m# TODO(After 1.13 release): Remove the deprecated SymbolicContext\u001b[39;00m\n\u001b[0;32m     33\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_exporter_states\u001b[39;00m \u001b[39mimport\u001b[39;00m ExportTypes, SymbolicContext\n",
      "File \u001b[1;32me:\\Unity Projects\\python_env\\mlagents-20-env\\lib\\site-packages\\torch\\onnx\\symbolic_opset11.py:12\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorch\u001b[39;00m \u001b[39mimport\u001b[39;00m _C\n\u001b[0;32m     11\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_C\u001b[39;00m \u001b[39mimport\u001b[39;00m _onnx \u001b[39mas\u001b[39;00m _C_onnx\n\u001b[1;32m---> 12\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39monnx\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[0;32m     13\u001b[0m     _type_utils,\n\u001b[0;32m     14\u001b[0m     errors,\n\u001b[0;32m     15\u001b[0m     symbolic_helper,\n\u001b[0;32m     16\u001b[0m     symbolic_opset10 \u001b[39mas\u001b[39;00m opset10,\n\u001b[0;32m     17\u001b[0m     symbolic_opset9 \u001b[39mas\u001b[39;00m opset9,\n\u001b[0;32m     18\u001b[0m     utils,\n\u001b[0;32m     19\u001b[0m )\n\u001b[0;32m     20\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39monnx\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_globals\u001b[39;00m \u001b[39mimport\u001b[39;00m GLOBALS\n\u001b[0;32m     21\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39monnx\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_internal\u001b[39;00m \u001b[39mimport\u001b[39;00m _beartype, jit_utils, registration\n",
      "File \u001b[1;32me:\\Unity Projects\\python_env\\mlagents-20-env\\lib\\site-packages\\torch\\onnx\\utils.py:34\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\n\u001b[0;32m     33\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_C\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_onnx\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39m_C_onnx\u001b[39;00m\n\u001b[1;32m---> 34\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mjit\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_trace\u001b[39;00m\n\u001b[0;32m     35\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mserialization\u001b[39;00m\n\u001b[0;32m     36\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorch\u001b[39;00m \u001b[39mimport\u001b[39;00m _C\n",
      "File \u001b[1;32me:\\Unity Projects\\python_env\\mlagents-20-env\\lib\\site-packages\\torch\\jit\\__init__.py:24\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[39m# These are imported so users can access them from the `torch.jit` module\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_jit_internal\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[0;32m     11\u001b[0m     Final,\n\u001b[0;32m     12\u001b[0m     Future,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     22\u001b[0m     unused,\n\u001b[0;32m     23\u001b[0m )\n\u001b[1;32m---> 24\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mjit\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_script\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[0;32m     25\u001b[0m     script,\n\u001b[0;32m     26\u001b[0m     Attribute,\n\u001b[0;32m     27\u001b[0m     ScriptModule,\n\u001b[0;32m     28\u001b[0m     script_method,\n\u001b[0;32m     29\u001b[0m     RecursiveScriptClass,\n\u001b[0;32m     30\u001b[0m     RecursiveScriptModule,\n\u001b[0;32m     31\u001b[0m     ScriptWarning,\n\u001b[0;32m     32\u001b[0m     interface,\n\u001b[0;32m     33\u001b[0m     CompilationUnit,\n\u001b[0;32m     34\u001b[0m     ScriptFunction,\n\u001b[0;32m     35\u001b[0m     _ScriptProfile,\n\u001b[0;32m     36\u001b[0m     _unwrap_optional,\n\u001b[0;32m     37\u001b[0m )\n\u001b[0;32m     38\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mjit\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_trace\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[0;32m     39\u001b[0m     trace,\n\u001b[0;32m     40\u001b[0m     trace_module,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     50\u001b[0m     _get_trace_graph,\n\u001b[0;32m     51\u001b[0m )\n\u001b[0;32m     52\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mjit\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_async\u001b[39;00m \u001b[39mimport\u001b[39;00m fork, wait\n",
      "File \u001b[1;32me:\\Unity Projects\\python_env\\mlagents-20-env\\lib\\site-packages\\torch\\jit\\_script.py:28\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mjit\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mfrontend\u001b[39;00m \u001b[39mimport\u001b[39;00m get_jit_def, get_default_args, get_jit_class_def\n\u001b[0;32m     27\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_jit_internal\u001b[39;00m \u001b[39mimport\u001b[39;00m _qualified_name\n\u001b[1;32m---> 28\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mjit\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_fuser\u001b[39;00m \u001b[39mimport\u001b[39;00m _graph_for, _script_method_graph_for\n\u001b[0;32m     29\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mjit\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_state\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[0;32m     30\u001b[0m     _try_get_jit_cached_function,\n\u001b[0;32m     31\u001b[0m     _try_get_jit_cached_overloads,\n\u001b[0;32m     32\u001b[0m     _set_jit_function_cache,\n\u001b[0;32m     33\u001b[0m     _set_jit_overload_cache,\n\u001b[0;32m     34\u001b[0m )\n\u001b[0;32m     35\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39moverrides\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[0;32m     36\u001b[0m     has_torch_function, has_torch_function_unary, has_torch_function_variadic)\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1007\u001b[0m, in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:982\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:925\u001b[0m, in \u001b[0;36m_find_spec\u001b[1;34m(name, path, target)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:1349\u001b[0m, in \u001b[0;36mfind_spec\u001b[1;34m(cls, fullname, path, target)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:1321\u001b[0m, in \u001b[0;36m_get_spec\u001b[1;34m(cls, fullname, path, target)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:1446\u001b[0m, in \u001b[0;36mfind_spec\u001b[1;34m(self, fullname, target)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:87\u001b[0m, in \u001b[0;36m_path_stat\u001b[1;34m(path)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import time\n",
    "import torch\n",
    "\n",
    "\n",
    "def test_process(queue):\n",
    "    print(f\"Test process started\")\n",
    "    try:\n",
    "        while True:\n",
    "            time.sleep(.4)\n",
    "            dummy_t = torch.ones(30,30,30)\n",
    "            queue.put(dummy_t)\n",
    "            print(f\"===== TEST PROCESS PUT ::: {dummy_t.shape}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Exception in test process: {e}\")\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Create a child SimpleQueue and a child process\n",
    "    torch.set_default_device(\"cuda\")\n",
    "    queue = torch.multiprocessing.SimpleQueue()\n",
    "    test_process = torch.multiprocessing.Process(target=test_process, args=(queue,))\n",
    "    test_process.start()\n",
    "\n",
    "    while True:\n",
    "        if not queue.empty():\n",
    "            print(f\"-------->>> MAIN PROCESS GOT::: {queue.get()}\")\n",
    "        else:\n",
    "            time.sleep(.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DOES NOT WORK! \n",
    "import time\n",
    "import torch\n",
    "\n",
    "from mlagents import simple_queue_with_size\n",
    "\n",
    "def test_producer_func(queue):\n",
    "    torch.set_default_device(\"cuda\")\n",
    "    print(f\"Test process started\")\n",
    "    try:\n",
    "        while True:\n",
    "            dummy_t = torch.ones(1000, 30,30,30)\n",
    "            queue.put(dummy_t)\n",
    "            print(f\"===== TEST PROCESS PUT ::: {dummy_t.shape}\")\n",
    "            time.sleep(5)\n",
    "    except Exception as e:\n",
    "        print(f\"Exception in test process: {e}\")\n",
    "\n",
    "\n",
    "def test_trainer_func(trainer):\n",
    "    torch.set_default_device(\"cuda\")\n",
    "    queue = simple_queue_with_size.SimpleQueueWithSize()\n",
    "    test_process = torch.multiprocessing.Process(target=test_producer_func, args=(queue,))\n",
    "    test_process.start()\n",
    "    if not queue.empty():\n",
    "        print(f\"-------->>> MAIN PROCESS GOT::: {queue.get()}\")\n",
    "    else:\n",
    "        time.sleep(.001)\n",
    "\n",
    "    # trainer._initialize()\n",
    "    # while True:\n",
    "    #     trainer.advance_consumer()\n",
    "\n",
    "\n",
    "class Trainer:\n",
    "    def _initialize(self):\n",
    "        self.queue = simple_queue_with_size.SimpleQueueWithSize()\n",
    "        test_process = torch.multiprocessing.Process(target=test_producer_func, args=(self.queue,))\n",
    "        test_process.start()\n",
    "\n",
    "    def advance_consumer(self):\n",
    "        if not self.queue.empty():\n",
    "            print(f\"-------->>> MAIN PROCESS GOT::: {self.queue.get()}\")\n",
    "        else:\n",
    "            time.sleep(.001)\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Create a child SimpleQueue and a child process\n",
    "    torch.set_default_device(\"cuda\")\n",
    "    trainer = Trainer()\n",
    "    trainer_process = torch.multiprocessing.Process(target=test_trainer_func, args=(trainer,))\n",
    "    trainer_process.start()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ALSO DOES NOT WORK!\n",
    "\n",
    "# DOES NOT WORK! \n",
    "import time\n",
    "import torch\n",
    "\n",
    "from mlagents import simple_queue_with_size\n",
    "\n",
    "def test_producer_func(queue):\n",
    "    torch.set_default_device(\"cuda\")\n",
    "    print(f\"Test process started\")\n",
    "    try:\n",
    "        while True:\n",
    "            dummy_t = torch.ones(1000, 30,30,30)\n",
    "            queue.put(dummy_t)\n",
    "            print(f\"===== TEST PROCESS PUT ::: {dummy_t.shape}\")\n",
    "            time.sleep(5)\n",
    "    except Exception as e:\n",
    "        print(f\"Exception in test process: {e}\")\n",
    "\n",
    "\n",
    "def test_trainer_func(trainer):\n",
    "    torch.set_default_device(\"cuda\")\n",
    "    queue = simple_queue_with_size.SimpleQueueWithSize()\n",
    "    test_process = torch.multiprocessing.Process(target=test_producer_func, args=(queue,))\n",
    "    test_process.start()\n",
    "    if not queue.empty():\n",
    "        print(f\"-------->>> MAIN PROCESS GOT::: {queue.get()}\")\n",
    "    else:\n",
    "        time.sleep(.001)\n",
    "\n",
    "    # trainer._initialize()\n",
    "    # while True:\n",
    "    #     trainer.advance_consumer()\n",
    "\n",
    "\n",
    "class Trainer:\n",
    "    def _initialize(self):\n",
    "        self.queue = simple_queue_with_size.SimpleQueueWithSize()\n",
    "        test_process = torch.multiprocessing.Process(target=test_producer_func, args=(self.queue,))\n",
    "        test_process.start()\n",
    "\n",
    "    def advance_consumer(self):\n",
    "        if not self.queue.empty():\n",
    "            print(f\"-------->>> MAIN PROCESS GOT::: {self.queue.get()}\")\n",
    "        else:\n",
    "            time.sleep(.001)\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Create a child SimpleQueue and a child process\n",
    "    torch.set_default_device(\"cuda\")\n",
    "    trainer = Trainer()\n",
    "    trainer_process = torch.multiprocessing.Process(target=test_trainer_func, args=(trainer,))\n",
    "    trainer_process.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "EOF while scanning triple-quoted string literal (3734864581.py, line 65)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[5], line 65\u001b[1;36m\u001b[0m\n\u001b[1;33m    ===== TEST PROCESS PUT ::: torch.Size([1000, 30, 30, 30]) with num non ones: 27000000 non ones before: 27000000\u001b[0m\n\u001b[1;37m                                                                                                                   \n^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m EOF while scanning triple-quoted string literal\n"
     ]
    }
   ],
   "source": [
    "# WEIRD ASS BEHAVIOR, STARTS WORKING AFTER A FEW ITERATIIONS: \n",
    "from tabnanny import check\n",
    "import time\n",
    "import torch\n",
    "\n",
    "from mlagents import simple_queue_with_size\n",
    "from mlagents.trainers.torch_entities.utils import ModelUtils\n",
    "\n",
    "\n",
    "def test_producer_func(queue):\n",
    "    torch.set_default_device(\"cuda\")\n",
    "    print(f\"Test process started\")\n",
    "    try:\n",
    "        while True:\n",
    "            time.sleep(5)\n",
    "            dummy_t = torch.ones(1000, 30,30,30)\n",
    "            non_ones = torch.sum(dummy_t == 1)\n",
    "            queue.put(dummy_t)\n",
    "            print(f\"===== TEST PROCESS PUT ::: {dummy_t.shape} with num non ones: {torch.sum(dummy_t == 1)} non ones before: {non_ones} \")\n",
    "    except Exception as e:\n",
    "        print(f\"Exception in test process: {e}\")\n",
    "\n",
    "\n",
    "def test_trainer_func(trainer):\n",
    "    torch.set_default_device(\"cuda\")\n",
    "    trainer._initialize()\n",
    "    while True:\n",
    "        trainer.advance_consumer()\n",
    "\n",
    "\n",
    "class Trainer:\n",
    "    def _initialize(self):\n",
    "        self.queue = simple_queue_with_size.SimpleQueueWithSize()\n",
    "        test_process = torch.multiprocessing.Process(target=test_producer_func, args=(self.queue,))\n",
    "        test_process.start()\n",
    "\n",
    "    def advance_consumer(self):\n",
    "        if not self.queue.empty():\n",
    "            item = self.queue.get()\n",
    "            print(f\"-------->>> MAIN PROCESS GOT TENSOR num non ones::: {torch.sum(item == 1)}\")\n",
    "            # print(f\"-------->>> MAIN PROCESS GOT::: {self.queue.get()}\")\n",
    "        else:\n",
    "            time.sleep(.001)\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Create a child SimpleQueue and a child process\n",
    "    torch.set_default_device(\"cuda\")\n",
    "    trainer = Trainer()\n",
    "    trainer_process = torch.multiprocessing.Process(target=test_trainer_func, args=(trainer,))\n",
    "    trainer_process.start()\n",
    "\n",
    "# OUTPUTS \n",
    "\"\"\"\n",
    "(mlagents-20-v2) E:\\Unity Projects\\python_env\\mlagents-20-clone\\ml-agents>python send_cuda_test.py\n",
    "Test process started\n",
    "===== TEST PROCESS PUT ::: torch.Size([1000, 30, 30, 30]) with num non ones: 0 non ones before: 27000000\n",
    "-------->>> MAIN PROCESS GOT TENSOR num non ones::: 0\n",
    "===== TEST PROCESS PUT ::: torch.Size([1000, 30, 30, 30]) with num non ones: 0 non ones before: 27000000\n",
    "-------->>> MAIN PROCESS GOT TENSOR num non ones::: 0\n",
    "-------->>> MAIN PROCESS GOT TENSOR num non ones::: 27000000\n",
    "===== TEST PROCESS PUT ::: torch.Size([1000, 30, 30, 30]) with num non ones: 27000000 non ones before: 27000000\n",
    "-------->>> MAIN PROCESS GOT TENSOR num non ones::: 27000000\n",
    "===== TEST PROCESS PUT ::: torch.Size([1000, 30, 30, 30]) with num non ones: 27000000 non ones before: 27000000\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DOESN'T WORK WITH SMALLER TENSORS EITHER - \n",
    "from tabnanny import check\n",
    "import time\n",
    "import torch\n",
    "\n",
    "from mlagents.simple_queue_with_size import SimpleQueueWithSize\n",
    "from mlagents.trainers.torch_entities.utils import ModelUtils\n",
    "\n",
    "\n",
    "def test_producer_func(queue : torch.multiprocessing.SimpleQueue):\n",
    "    torch.set_default_device(\"cuda\")\n",
    "    print(f\"Test process started\")\n",
    "    try:\n",
    "        while True:\n",
    "            time.sleep(5)\n",
    "            dummy_t = torch.ones(1, 1,1,30)\n",
    "            non_ones = torch.sum(dummy_t == 1)\n",
    "            queue.put(dummy_t)\n",
    "            print(f\"===== TEST PROCESS PUT ::: {dummy_t.shape} with num non ones: {torch.sum(dummy_t == 1)} non ones before: {non_ones} \")\n",
    "    except Exception as e:\n",
    "        print(f\"Exception in test process: {e}\")\n",
    "\n",
    "\n",
    "def test_trainer_func(trainer):\n",
    "    torch.set_default_device(\"cuda\")\n",
    "    queue = torch.multiprocessing.SimpleQueue()\n",
    "    test_process = torch.multiprocessing.Process(target=test_producer_func, args=(queue,))\n",
    "    test_process.start()\n",
    "    # trainer._initialize()\n",
    "    while True:\n",
    "        item = queue.get()\n",
    "        print(f\"-------->>> MAIN PROCESS GOT TENSOR num non ones::: {torch.sum(item == 1)}\")\n",
    "        # print(f\"-------->>> MAIN PROCESS GOT::: {self.queue.get()}\")\n",
    "        time.sleep(.001)\n",
    "\n",
    "    #     trainer.advance_consumer()\n",
    "\n",
    "\n",
    "class Trainer:\n",
    "    def _initialize(self):\n",
    "        self.queue = torch.multiprocessing.SimpleQueue()\n",
    "        test_process = torch.multiprocessing.Process(target=test_producer_func, args=(self.queue,))#\n",
    "        test_process.start()\n",
    "\n",
    "    def advance_consumer(self):\n",
    "        if not self.queue.empty():\n",
    "            item = self.queue.get()\n",
    "            print(f\"-------->>> MAIN PROCESS GOT TENSOR num non ones::: {torch.sum(item == 1)}\")\n",
    "            # print(f\"-------->>> MAIN PROCESS GOT::: {self.queue.get()}\")\n",
    "        else:\n",
    "            time.sleep(.001)\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Create a child SimpleQueue and a child process\n",
    "    torch.set_default_device(\"cuda\")\n",
    "    trainer = Trainer()\n",
    "    trainer_process = torch.multiprocessing.Process(target=test_trainer_func, args=(trainer,))\n",
    "    trainer_process.start()\n",
    "\n",
    "# OUTPUTS\n",
    "\"\"\"\n",
    "(mlagents-20-v2) E:\\Unity Projects\\python_env\\mlagents-20-clone\\ml-agents>python send_cuda_test.py\n",
    "Test process started\n",
    "===== TEST PROCESS PUT ::: torch.Size([1, 1, 1, 30]) with num non ones: 0 non ones before: 0\n",
    "-------->>> MAIN PROCESS GOT TENSOR num non ones::: 0\n",
    "===== TEST PROCESS PUT ::: torch.Size([1, 1, 1, 30]) with num non ones: 30 non ones before: 30\n",
    "-------->>> MAIN PROCESS GOT TENSOR num non ones::: 30\n",
    "===== TEST PROCESS PUT ::: torch.Size([1, 1, 1, 30]) with num non ones: 30 non ones before: 30\n",
    "-------->>> MAIN PROCESS GOT TENSOR num non ones::: 30\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PYTROCH MINIMAL REPRO\n",
    "import time\n",
    "import torch\n",
    "\n",
    "def test_producer_func(queue : torch.multiprocessing.SimpleQueue):\n",
    "    torch.set_default_device(\"cuda\")\n",
    "    while True:\n",
    "        dummy_t = torch.ones(1, 1,1,30)\n",
    "        non_ones = torch.sum(torch.isclose(dummy_t, torch.ones(1)))# torch.sum(dummy_t == 1)\n",
    "        queue.put(dummy_t)\n",
    "        print(f\"===== TEST PROCESS PUT ::: {dummy_t.shape} with num non ones: {torch.sum(torch.isclose(dummy_t, torch.ones(1)))} non ones before: {non_ones} \")\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    torch.set_default_device(\"cuda\")\n",
    "    queue = torch.multiprocessing.SimpleQueue()\n",
    "    producer_process = torch.multiprocessing.Process(target=test_producer_func, args=(queue,))\n",
    "    producer_process.start()\n",
    "    while True:\n",
    "        if not queue.empty():\n",
    "            item = queue.get()\n",
    "            print(f\"-------->>> MAIN PROCESS GOT TENSOR num non ones::: {torch.sum(torch.isclose(item, torch.ones(1)))}\")\n",
    "        else:\n",
    "            time.sleep(.001)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VICE VERSA DOES NOT WORK EITHER \n",
    "\n",
    "\n",
    "def test_producer_func(queue : torch.multiprocessing.SimpleQueue):\n",
    "    torch.set_default_device(\"cuda\")\n",
    "    while True:\n",
    "        if not queue.empty():\n",
    "            item = queue.get()\n",
    "            print(f\"-------->>> test_producer_func TENSOR num non ones::: {torch.sum(item == 1)}\")\n",
    "        else:\n",
    "            time.sleep(.001)\n",
    "        # dummy_t = torch.ones(1, 1,1,30)\n",
    "        # non_ones = torch.sum(dummy_t == 1)\n",
    "        # queue.put(dummy_t)\n",
    "        # print(f\"===== TEST PROCESS PUT ::: {dummy_t.shape} with num non ones: {torch.sum(dummy_t == 1)} non ones before: {non_ones} \")\n",
    "        # time.sleep(3)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    torch.set_default_device(\"cuda\")\n",
    "    queue = torch.multiprocessing.SimpleQueue()\n",
    "    producer_process = torch.multiprocessing.Process(target=test_producer_func, args=(queue,))\n",
    "    producer_process.start()\n",
    "    while True:\n",
    "        # if not queue.empty():\n",
    "        #     item = queue.get()\n",
    "        #     print(f\"-------->>> MAIN PROCESS GOT TENSOR num non ones::: {torch.sum(item == 1)}\")\n",
    "        # else:\n",
    "        #     time.sleep(.001)\n",
    "        dummy_t = torch.ones(1, 1,1,30)\n",
    "        non_ones = torch.sum(dummy_t == 1)\n",
    "        queue.put(dummy_t)\n",
    "        print(f\"===== __main__ PROCESS PUT ::: {dummy_t.shape} with num non ones: {torch.sum(dummy_t == 1)} non ones before: {non_ones} \")\n",
    "        time.sleep(3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlagents-20-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
